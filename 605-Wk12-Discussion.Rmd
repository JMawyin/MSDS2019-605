---
title: "605 Discussion 12"
author: "Jose Mawyin"
date: "11/16/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```


## Linear Regression Fit to Boston Housing Data

1. Introduction
2. Data
3. Linear Regresssion
4. Analysis
5. Comments

### 1. Introduction

This analysis will use housing data for 506 census tracts of Boston from the 1970 census collected by Harrison and Rubinfeld (1979) to test the validity of using linear regression models to predict the median value of owner-occupied homes.

```{r, include=FALSE}
library(mlbench)
data(BostonHousing2)
dim(BostonHousing2)
BostonHousing2 <- filter(BostonHousing2, medv < 50)
dim(BostonHousing2)
```


### 2. Data

The original data are 506 observations on 14 variables, medv being the target variable:

1.  *crim*
per capita crime rate by town
2.  *zn*
proportion of residential land zoned for lots over 25,000 sq.ft
3.  *indus*
proportion of non-retail business acres per town
4.  $\color{red}{\text{chas}}$.
Charles River dummy **dichotomous** variable (= 1 if tract bounds river; 0 otherwise)
5.  *nox*
nitric oxides concentration (parts per 10 million)
6.  *rm*
average number of rooms per dwelling
7.  *age*
proportion of owner-occupied units built prior to 1940
8.  *dis*
weighted distances to five Boston employment centres
9.  *rad*
index of accessibility to radial highways
10. *tax*
full-value property-tax rate per USD 10,000
11. *ptratio*
pupil-teacher ratio by town
12. *b*
1000(B-0.63)^2     where B is the proportion of blacks by town
13. *lstat*
percentage of lower status of the population



The corrected data set has the following additional columns:

14. *cmedv*
corrected median value of owner-occupied homes in USD 1000's
15. *town*
name of town
16. *tract*
census tract
17. *lon*
longitude of census tract
18. *lat*
latitude of census tract

Below is a histogram showing a distribution of the median value of owner-occupied homes in USD 1000's. 

```{r, echo=FALSE}
attach(BostonHousing2)
hist(medv)
```


### 3. Linear Regresssion

Three different linear regression models were generated. The first one "Boston_cmedv.lm" that took into account all independent variables available in the dataset.

```{r,tidy=TRUE, tidy.opts=list(width.cutoff=60)}
Boston_cmedv.lm <- lm(medv ~ crim + zn + indus + chas +  nox + rm + dis + age + rad + ptratio + b +lstat, data=BostonHousing2)
```

A second model that used Backward Elimination of Factors to remove those independent variables with a low p value indicating that did not contribute much to the response variable "medv".

```{r}
Boston_cmedv.lmV2 <- lm(medv ~  nox + rm + dis + ptratio + b + lstat, data=BostonHousing2)
```

A third model that tried to better fit independent variables $\color{red}{\text{dis}}$ and $\color{red}{\text{lstat}}$ into the model by considering them as **non-linear** variables.

```{r}
Boston_cmedv.lmV3 <- lm(medv ~ nox + rm + log2(dis) + ptratio + b + log(lstat, base = 1/2), data=BostonHousing2)
```


### 4. Analysis

The first model using all 12 independent variables had a $R^{2}$ of *0.7678*. The second model that used only 6 independent variables had a $R^{2}$ of *0.7513*. The third model that took into account non-linearities in some of the 6 independent variables from model 2 had a $R^{2}$ of *0.7837*.

```{r}
summary(Boston_cmedv.lm)
summary(Boston_cmedv.lmV2)
summary(Boston_cmedv.lmV3)
```

We notice an improvement in the residuals when we take into account non-linearities in some of the 6 independent variables from model 2. Comparing the rightmost residual plot before we see a more even spread around the zeroth line as compared to the middle plot that use the same independent variables as is.

```{r}
par(mfrow=c(1,3))
plot(fitted(Boston_cmedv.lm),resid(Boston_cmedv.lm))
plot(fitted(Boston_cmedv.lmV2),resid(Boston_cmedv.lmV2))
plot(fitted(Boston_cmedv.lmV3),resid(Boston_cmedv.lmV3))
```

Improvements in the fit are not obvious in the Q-Q plots below. Most changes happen in a reduction in the spread of the Sample Quartiles from -10:+15 to -10:+10 when taking into account  non-linearities in the independent variables. Despite some effort, it was not possible to identify the causes for the tails to diverge from the normal distribution fit line. 

```{r}
par(mfrow=c(1,3))
qqnorm(resid(Boston_cmedv.lm), main = "All Vars")
qqline(resid(Boston_cmedv.lm))
qqnorm(resid(Boston_cmedv.lmV2), main = "Reduced Vars")
qqline(resid(Boston_cmedv.lmV2))
qqnorm(resid(Boston_cmedv.lmV3), main = "N.L. Reduced Vars")
qqline(resid(Boston_cmedv.lmV3))
```

### 5. Comments

We have seen how it was possible to reduce by half the number of independent variables in a linear regression model that still produced a similar $R^{2}$ value that describes the measured data. We also saw how taking into account non-linearities in independent variables was used to generate a better fit to the linear regression model.

